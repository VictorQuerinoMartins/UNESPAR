{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "dynsYLcSTomO",
        "outputId": "d994aadf-76a5-43f5-fefc-ec41552a7bb2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# CÉLULA 1: Enviar o arquivo kaggle.json para o Colab\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Ao rodar esta célula, um botão de \"Escolher arquivos\" vai aparecer.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Selecione o arquivo 'kaggle.json' que você baixou do Kaggle.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPor favor, faça o upload do seu arquivo kaggle.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m files.upload()\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# CÉLULA 1: Enviar o arquivo kaggle.json para o Colab\n",
        "# Ao rodar esta célula, um botão de \"Escolher arquivos\" vai aparecer.\n",
        "# Selecione o arquivo 'kaggle.json' que você baixou do Kaggle.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Por favor, faça o upload do seu arquivo kaggle.json\")\n",
        "files.upload()\n",
        "\n",
        "# ---\n",
        "# Agora, execute a próxima célula para configurar a API\n",
        "# ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMXjp0J-WDOU",
        "outputId": "aabe132e-9eda-4251-a685-5d506215fd3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A sintaxe do comando est� incorreta.\n",
            "'cp' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API do Kaggle configurada com sucesso!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'chmod' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 2: Configurar a API do Kaggle no ambiente do Colab\n",
        "# Este código move o arquivo json para o lugar certo para que a API funcione.\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"API do Kaggle configurada com sucesso!\")\n",
        "\n",
        "# ---\n",
        "# Agora, execute a próxima célula para baixar o dataset\n",
        "# ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mutw9ZsQWI91",
        "outputId": "e75c727c-92fb-4b7e-e500-2742fe5b26a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset baixado. Agora vamos descompactar.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 3: Baixar o dataset de veículos do Kaggle\n",
        "# Usaremos um dataset bem conhecido e estruturado.\n",
        "# O comando !kaggle ... é como se estivéssemos digitando no terminal.\n",
        "\n",
        "!kaggle datasets download -d lyensoetanto/vehicle-images-dataset\n",
        "\n",
        "print(\"\\nDataset baixado. Agora vamos descompactar.\")\n",
        "\n",
        "# ---\n",
        "# Agora, execute a próxima célula para descompactar o arquivo\n",
        "# ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEyZhjfgjiaj",
        "outputId": "9d0b07d8-15e5-4377-fecd-20805e639725"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'vehicle-images-dataset.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# CÉLULA 4: Descompactar o arquivo .zip\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# O arquivo baixado precisa ser extraído para podermos usar as imagens.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvehicle-images-dataset.zip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[32m      7\u001b[39m     zip_ref.extractall(\u001b[33m'\u001b[39m\u001b[33mvehicle_dataset\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset descompactado na pasta \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvehicle_dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1331\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1333\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'vehicle-images-dataset.zip'"
          ]
        }
      ],
      "source": [
        "# CÉLULA 4: Descompactar o arquivo .zip\n",
        "# O arquivo baixado precisa ser extraído para podermos usar as imagens.\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('vehicle-images-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('vehicle_dataset')\n",
        "\n",
        "print(\"Dataset descompactado na pasta 'vehicle_dataset'\")\n",
        "\n",
        "# ---\n",
        "# Finalmente, execute a última célula com o código de treinamento!\n",
        "# ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "djo6jHW0k4Tm",
        "outputId": "9297ad21-7944-4511-b27b-0bb59197a812"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# CÉLULA 5: Código de Treinamento da Rede Neural (ajustado para rodar localmente)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# CÉLULA 5: Código de Treinamento da Rede Neural (ajustado para rodar localmente)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# --- AJUSTE O CAMINHO AQUI ---\n",
        "# 1. Apontar para a pasta do dataset no seu computador.\n",
        "# Use 'r' antes do caminho no Windows para evitar erros com a barra invertida (\\).\n",
        "base_dir = r'C:\\Users\\yguin\\OneDrive\\Documentos\\GitHub\\UNESPAR\\IA\\CNNs\\ClassificadorDeVeiculos\\dataset'\n",
        "\n",
        "# Verificação para garantir que o caminho existe antes de prosseguir\n",
        "if not os.path.exists(base_dir):\n",
        "    raise FileNotFoundError(f\"ERRO: O caminho '{base_dir}' não foi encontrado. Verifique se está correto.\")\n",
        "else:\n",
        "    print(f\"Dataset encontrado em: {base_dir}\")\n",
        "    print(f\"Classes no diretório: {os.listdir(base_dir)}\")\n",
        "\n",
        "# --- DEFINIÇÃO DOS PARÂMETROS ---\n",
        "# 2. Definir parâmetros para as imagens e o treinamento\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION_SPLIT = 0.2 # Usaremos 20% dos dados para validação/teste\n",
        "\n",
        "# --- CRIAÇÃO DOS DATASETS DE TREINO E TESTE ---\n",
        "# 3. Criar os datasets a partir do mesmo diretório, dividindo-os em treino e teste.\n",
        "# O TensorFlow fará a divisão automaticamente usando validation_split.\n",
        "\n",
        "# Conjunto de dados para TREINAMENTO (80% dos dados)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    label_mode='int',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Conjunto de dados para TESTE/VALIDAÇÃO (20% dos dados)\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    label_mode='int',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes carregadas pelo TensorFlow:\", class_names)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# --- OTIMIZAÇÃO E CONSTRUÇÃO DO MODELO ---\n",
        "# Otimizar os datasets para melhor desempenho durante o treinamento\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Criar a arquitetura do modelo de Rede Neural Convolucional (CNN)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(class_names), activation='softmax') # Camada de saída com o número de classes\n",
        "])\n",
        "\n",
        "# Compilar o modelo, definindo o otimizador, a função de perda e as métricas\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Imprimir um resumo da arquitetura do modelo\n",
        "model.summary()\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- TREINAMENTO E AVALIAÇÃO ---\n",
        "# Treinar o modelo\n",
        "epochs = 15\n",
        "print(f\"Iniciando o treinamento por {epochs} épocas...\")\n",
        "history = model.fit(train_ds, validation_data=test_ds, epochs=epochs)\n",
        "print(\"Treinamento finalizado!\")\n",
        "\n",
        "# Gerar e exibir a Matriz de Confusão para avaliar o desempenho\n",
        "print(\"Gerando a Matriz de Confusão...\")\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Extrai os rótulos e previsões do conjunto de teste\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "# Cria e plota a matriz\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
        "plt.title(\"Matriz de Confusão - Classificador de Veículos\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
